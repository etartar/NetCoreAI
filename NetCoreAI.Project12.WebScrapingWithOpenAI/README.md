# ğŸŒ NetCoreAI.Project12 - Web Scraping with OpenAI

HtmlAgilityPack ve OpenAI GPT-3.5-turbo API kullanarak web sayfalarÄ±ndan iÃ§erik Ã§ekme ve analiz etme .NET 10 konsol uygulamasÄ±.

## ğŸ“‹ Ã–zellikler

- âœ… HtmlAgilityPack ile web scraping
- âœ… OpenAI GPT ile iÃ§erik analizi ve Ã¶zetleme
- âœ… TÃ¼rkÃ§e Ã§Ä±ktÄ± desteÄŸi
- âœ… User Secrets ile gÃ¼venli API key yÃ¶netimi
- âœ… Otomatik HTML temizleme

## ğŸ› ï¸ Gereksinimler

- .NET 10 SDK
- OpenAI API Key ([OpenAI Platform](https://platform.openai.com/api-keys) Ã¼zerinden alabilirsiniz)
- Ä°nternet baÄŸlantÄ±sÄ±

## ğŸ“¦ KullanÄ±lan Paketler

```xml
<PackageReference Include="HtmlAgilityPack" Version="1.12.4" />
<PackageReference Include="Microsoft.Extensions.Configuration.UserSecrets" Version="10.0.3" />
```

## ğŸš€ Kurulum

### 1. Projeyi klonlayÄ±n veya indirin

```bash
git clone https://github.com/etartar/NetCoreAI
cd NetCoreAI/NetCoreAI.Project12.WebScrapingWithOpenAI
```

### 2. API Key'i kaydedin

```bash
dotnet user-secrets set "OpenAI:ApiKey" "YOUR_OPENAI_API_KEY"
```

> **Not:** API key'inizi [OpenAI Platform](https://platform.openai.com/api-keys) adresinden oluÅŸturabilirsiniz.

### 3. BaÄŸÄ±mlÄ±lÄ±klarÄ± yÃ¼kleyin

```bash
dotnet restore
```

### 4. UygulamayÄ± Ã§alÄ±ÅŸtÄ±rÄ±n

```bash
dotnet run
```

## ğŸ’¡ KullanÄ±m

Uygulama Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda analiz etmek istediÄŸiniz web sitesinin URL'sini girin:

```
LÃ¼ften analiz yapmak istediÄŸiniz web sitesinin URL'sini giriniz: https://example.com

Web sayfasÄ± iÃ§eriÄŸi: 

 AI Analizi (Web SayfasÄ± Ä°Ã§eriÄŸi): 
Bu web sitesi [iÃ§erik Ã¶zeti]... [AI tarafÄ±ndan TÃ¼rkÃ§e Ã¶zet]
```

### Ã–rnek KullanÄ±mlar:

**Haber Sitesi Analizi:**
```
Input:  https://www.bbc.com/turkce
Output: Web sitesi TÃ¼rkiye ve dÃ¼nyadan gÃ¼ncel haberleri iÃ§ermektedir...
```

**Blog Analizi:**
```
Input:  https://medium.com/@username/article
Output: Bu blog yazÄ±sÄ± [konu] hakkÄ±nda detaylÄ± bilgi vermektedir...
```

**ÃœrÃ¼n SayfasÄ± Analizi:**
```
Input:  https://www.example.com/product/123
Output: Bu Ã¼rÃ¼n sayfasÄ± [Ã¼rÃ¼n adÄ±] iÃ§in fiyat ve Ã¶zellik bilgilerini iÃ§erir...
```

## ğŸ¯ KullanÄ±m AlanlarÄ±

### Ä°Ã§erik Analizi
- Rakip analizi
- Ä°Ã§erik benchmark
- SEO analizi
- Trend takibi

### Haber ve Medya
- Haber Ã¶zetleme
- Trend analizi
- Konu sÄ±nÄ±flandÄ±rma
- Kaynak doÄŸrulama

### E-Ticaret
- ÃœrÃ¼n bilgisi toplama
- Fiyat karÅŸÄ±laÅŸtÄ±rma
- ÃœrÃ¼n Ã¶zellikleri Ã§Ä±karma
- MÃ¼ÅŸteri yorumlarÄ± analizi

### Akademik AraÅŸtÄ±rma
- Veri toplama
- Ä°Ã§erik analizi
- Bilgi Ã§Ä±karma
- LiteratÃ¼r tarama

## ğŸ”§ YapÄ±landÄ±rma

### FarklÄ± HTML Elementleri Ã‡ekme

Sadece belirli elementleri almak iÃ§in:

```csharp
// Sadece baÅŸlÄ±klarÄ± al
var headers = doc.DocumentNode.SelectNodes("//h1 | //h2 | //h3");

// Sadece paragraflarÄ± al
var paragraphs = doc.DocumentNode.SelectNodes("//p");

// Belirli bir div iÃ§eriÄŸini al
var content = doc.DocumentNode.SelectSingleNode("//div[@class='content']");
```

### FarklÄ± Analiz TÃ¼rleri

Sistem mesajÄ±nÄ± deÄŸiÅŸtirerek farklÄ± analizler yapabilirsiniz:

```csharp
// Ã–zet iÃ§in
new { role = "system", content = "Metni kÄ±sa ve Ã¶z ÅŸekilde Ã¶zetle." }

// Anahtar kelimeler iÃ§in
new { role = "system", content = "Bu metindeki en Ã¶nemli 5 anahtar kelimeyi Ã§Ä±kar." }

// Duygu analizi iÃ§in
new { role = "system", content = "Bu metnin genel tonunu ve duygusunu analiz et." }

// Kategori belirleme iÃ§in
new { role = "system", content = "Bu metni en uygun kategoriye atama yap (Teknoloji, Spor, Ekonomi, vb.)." }
```

### Ã‡oklu Sayfa Analizi

Birden fazla URL'yi analiz etmek iÃ§in:

```csharp
string[] urls = 
{
    "https://example.com/page1",
    "https://example.com/page2",
    "https://example.com/page3"
};

foreach (var url in urls)
{
    string content = await GetWebPageContentAsync(url);
    await AnalyzeWithAI(content, $"Sayfa: {url}");
}
```

## ğŸš€ GeliÅŸmiÅŸ Ã–zellikler

### Link Ã‡Ä±karma

Sayfadaki tÃ¼m linkleri Ã§Ä±karmak iÃ§in:

```csharp
var links = doc.DocumentNode.SelectNodes("//a[@href]");
foreach (var link in links)
{
    string url = link.GetAttributeValue("href", "");
    string text = link.InnerText;
    Console.WriteLine($"{text}: {url}");
}
```

### GÃ¶rsel URL'lerini Alma

Sayfadaki tÃ¼m gÃ¶rselleri almak iÃ§in:

```csharp
var images = doc.DocumentNode.SelectNodes("//img[@src]");
foreach (var img in images)
{
    string src = img.GetAttributeValue("src", "");
    string alt = img.GetAttributeValue("alt", "");
    Console.WriteLine($"{alt}: {src}");
}
```

### Tablo Verilerini Ã‡Ä±karma

HTML tablolarÄ±ndan veri Ã§ekmek iÃ§in:

```csharp
var tables = doc.DocumentNode.SelectNodes("//table");
foreach (var table in tables)
{
    var rows = table.SelectNodes(".//tr");
    foreach (var row in rows)
    {
        var cells = row.SelectNodes(".//td | .//th");
        if (cells != null)
        {
            var cellValues = cells.Select(c => c.InnerText).ToList();
            Console.WriteLine(string.Join(" | ", cellValues));
        }
    }
}
```

### Meta Bilgilerini Alma

Sayfa meta verilerini Ã§Ä±karmak iÃ§in:

```csharp
var title = doc.DocumentNode.SelectSingleNode("//title")?.InnerText;
var description = doc.DocumentNode.SelectSingleNode("//meta[@name='description']")?.GetAttributeValue("content", "");
var keywords = doc.DocumentNode.SelectSingleNode("//meta[@name='keywords']")?.GetAttributeValue("content", "");

Console.WriteLine($"BaÅŸlÄ±k: {title}");
Console.WriteLine($"AÃ§Ä±klama: {description}");
Console.WriteLine($"Anahtar Kelimeler: {keywords}");
```

## ğŸ“Š Performans Ä°puÃ§larÄ±

### HTML Temizleme

Gereksiz whitespace'leri temizlemek iÃ§in:

```csharp
string cleanText = System.Text.RegularExpressions.Regex.Replace(bodyText, @"\s+", " ").Trim();
```

### Token Limitine Dikkat

Uzun iÃ§erikleri parÃ§alayÄ±n:

```csharp
const int maxChars = 10000;
if (webContent.Length > maxChars)
{
    webContent = webContent.Substring(0, maxChars) + "...";
}
```

### Retry MekanizmasÄ±

Web sitesine baÄŸlanÄ±rken hata durumunda yeniden deneme:

```csharp
int retryCount = 3;
for (int i = 0; i < retryCount; i++)
{
    try
    {
        var doc = await web.LoadFromWebAsync(url);
        return doc;
    }
    catch (Exception ex)
    {
        if (i == retryCount - 1) throw;
        await Task.Delay(1000 * (i + 1)); // Exponential backoff
    }
}
```

## ğŸ”’ GÃ¼venlik ve Etik

### Robots.txt KontrolÃ¼

Web scraping yaparken her zaman robots.txt dosyasÄ±nÄ± kontrol edin:

```csharp
var robotsUrl = new Uri(new Uri(url), "/robots.txt").ToString();
// robots.txt kontrol et
```

### User-Agent Ayarlama

SaygÄ±lÄ± bir bot olun:

```csharp
var web = new HtmlWeb();
web.UserAgent = "Mozilla/5.0 (compatible; MyBot/1.0; +https://mywebsite.com/bot)";
```

### Rate Limiting

Sunucuyu yormamak iÃ§in istekler arasÄ±nda bekleme:

```csharp
await Task.Delay(2000); // 2 saniye bekle
```

### Yasal UyarÄ±

âš ï¸ **Ã–NEMLÄ°**: 
- Web scraping yaparken sitenin kullanÄ±m ÅŸartlarÄ±nÄ± okuyun
- robots.txt dosyasÄ±na uyun
- Telif haklarÄ±na saygÄ± gÃ¶sterin
- KiÅŸisel verileri koruyun (GDPR/KVKK)
- Sunucuyu aÅŸÄ±rÄ± yÃ¼klemeyin

## ğŸ“ API Limitleri ve FiyatlandÄ±rma

- **GPT-3.5-turbo**: ~$0.0005 / 1K token (input), ~$0.0015 / 1K token (output)
- Ortalama bir sayfa analizi: ~2000-3000 token
- 100 sayfa analizi maliyeti: ~$0.75 - $1.50

## ğŸ› Hata AyÄ±klama

### "Ä°Ã§erik bulunamadÄ±" hatasÄ±:

```csharp
// Alternatif selektÃ¶rler deneyin
var bodyText = doc.DocumentNode.SelectSingleNode("//body")?.InnerText 
    ?? doc.DocumentNode.SelectSingleNode("//main")?.InnerText
    ?? doc.DocumentNode.InnerText;
```

### JavaScript ile yÃ¼klenen iÃ§erik:

HtmlAgilityPack JavaScript'i Ã§alÄ±ÅŸtÄ±rmaz. Selenium veya Puppeteer kullanÄ±n:

```bash
dotnet add package Selenium.WebDriver
dotnet add package Selenium.WebDriver.ChromeDriver
```

### HTTP HatalarÄ±:

```csharp
try
{
    var doc = await web.LoadFromWebAsync(url);
}
catch (WebException ex)
{
    Console.WriteLine($"Web hatasÄ±: {ex.Message}");
    // 404, 403, vb. hatalarÄ± yÃ¶net
}
```

## ğŸ“š Ä°lgili Kaynaklar

- [HtmlAgilityPack Documentation](https://html-agility-pack.net/)
- [XPath Syntax](https://www.w3schools.com/xml/xpath_syntax.asp)
- [Web Scraping Best Practices](https://www.scrapehero.com/web-scraping-best-practices/)
- [Robots.txt Guide](https://developers.google.com/search/docs/crawling-indexing/robots/intro)

## ğŸ‘¨â€ğŸ’» GeliÅŸtirici

**Emir TARTAR**
- GitHub: [@etartar](https://github.com/etartar)

## ğŸ“„ Lisans

Bu proje eÄŸitim amaÃ§lÄ±dÄ±r.
